{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df = pd.read_csv(r'C:\\Users\\Hp\\Desktop\\work\\machine-learning-assignment-1-group-2\\notebooks\\student2_success_preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['student_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data For Model Traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable and the features\n",
    "X = df.drop('final_grade', axis=1)\n",
    "y = df['final_grade']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train Linear Regression Model (Baseline Model)\n",
    "\n",
    "Now, we will train the first model, a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the linear regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Linear Regression Model - MSE: {mse}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Linear Regression Model (Baseline Model)\n",
    "\n",
    "Now, we will train the first model, a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # alpha is the regularization strength\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"Ridge Regression Model - MSE: {mse_ridge}, R2: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lasso Regression Model\n",
    "\n",
    "Similarly, we can train a Lasso Regression model, which also uses regularization but with L1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Lasso regression model\n",
    "lasso_model = Lasso(alpha=0.1)  # alpha is the regularization strength\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"Lasso Regression Model - MSE: {mse_lasso}, R2: {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Model Performance\n",
    "\n",
    "Now, let's compare the performance of the three models based on their Mean Squared Error (MSE) and R2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison DataFrame\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Ridge Regression', 'Lasso Regression'],\n",
    "    'MSE': [mse, mse_ridge, mse_lasso],\n",
    "    'R2': [r2, r2_ridge, r2_lasso]\n",
    "})\n",
    "\n",
    "# Display the comparison\n",
    "print(model_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already performed some model evaluations, specifically for three types of regression models: Linear Regression, Ridge Regression, and Lasso Regression. The results you provided show the Mean Squared Error (MSE) and R-squared (R²) values for each model:\n",
    "\n",
    "1. **Linear Regression**:\n",
    "   - **MSE**: 10.41\n",
    "   - **R²**: 0.50\n",
    "\n",
    "2. **Ridge Regression**:\n",
    "   - **MSE**: 10.95\n",
    "   - **R²**: 0.47\n",
    "\n",
    "3. **Lasso Regression**:\n",
    "   - **MSE**: 10.59\n",
    "   - **R²**: 0.49\n",
    "\n",
    "### Analysis:\n",
    "- **MSE**: A lower value of MSE indicates a better fit of the model to the data. In this case, **Linear Regression** has the lowest MSE.\n",
    "- **R²**: The R² score indicates how well the model explains the variability in the target variable. A higher R² value indicates a better model fit. Here, **Linear Regression** also has the highest R².\n",
    "\n",
    "### Conclusion:\n",
    "- **Linear Regression** is the best performing model based on these metrics, as it has the lowest MSE and the highest R²."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 5. Analysis & Interpretation (All team members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Interpret Model Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting the model coefficients\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Linear Regression Coefficients': lr_coefficients,\n",
    "    'Ridge Regression Coefficients': ridge_coefficients,\n",
    "    'Lasso Regression Coefficients': lasso_coefficients\n",
    "})\n",
    "\n",
    "coefficients_df.set_index('Feature', inplace=True)\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Identify the Most Influential Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting coefficients by absolute value to identify the most influential features\n",
    "coefficients_df['Linear Regression Abs'] = coefficients_df['Linear Regression Coefficients'].abs()\n",
    "coefficients_df['Ridge Regression Abs'] = coefficients_df['Ridge Regression Coefficients'].abs()\n",
    "coefficients_df['Lasso Regression Abs'] = coefficients_df['Lasso Regression Coefficients'].abs()\n",
    "\n",
    "# Sorting by absolute values for each model\n",
    "sorted_linear = coefficients_df.sort_values('Linear Regression Abs', ascending=False)\n",
    "sorted_ridge = coefficients_df.sort_values('Ridge Regression Abs', ascending=False)\n",
    "sorted_lasso = coefficients_df.sort_values('Lasso Regression Abs', ascending=False)\n",
    "\n",
    "# Display sorted results\n",
    "print(\"Top Influential Features (Linear Regression):\")\n",
    "print(sorted_linear[['Linear Regression Coefficients']].head())\n",
    "\n",
    "print(\"\\nTop Influential Features (Ridge Regression):\")\n",
    "print(sorted_ridge[['Ridge Regression Coefficients']].head())\n",
    "\n",
    "print(\"\\nTop Influential Features (Lasso Regression):\")\n",
    "print(sorted_lasso[['Lasso Regression Coefficients']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression**:\n",
    "- **study_resources_Online Resources, Tutoring, Study Groups**: -4.93 (Negative impact)\n",
    "- **study_resources_Tutoring, Study Group**: 2.70 (Positive impact)\n",
    "- **family_support_Low**: -2.51 (Negative impact)\n",
    "- **study_resources_Textbooks, Tutoring, Study Group**: -1.73 (Negative impact)\n",
    "- **program_of_study_Engineering**: 1.53 (Positive impact)\n",
    "\n",
    "### **Ridge Regression**:\n",
    "- **family_support_Low**: -2.44 (Negative impact)\n",
    "- **study_resources_Online Resources, Tutoring, Study Groups**: -2.33 (Negative impact)\n",
    "- **previous_gpa**: 1.41 (Positive impact)\n",
    "- **program_of_study_Engineering**: 1.40 (Positive impact)\n",
    "- **attendance_rate**: 1.40 (Positive impact)\n",
    "\n",
    "### **Lasso Regression**:\n",
    "- **family_support_Low**: -1.61 (Negative impact)\n",
    "- **attendance_rate**: 1.36 (Positive impact)\n",
    "- **previous_gpa**: 1.30 (Positive impact)\n",
    "- **participation_score**: 0.94 (Positive impact)\n",
    "- **previous_course_failures**: -0.88 (Negative impact)\n",
    "\n",
    "### Interpretation:\n",
    "1. **Study Resources**: \n",
    "   - For **Linear and Ridge Regression**, the feature \"Online Resources, Tutoring, Study Groups\" has a significant negative impact on the target variable, while other study resource categories show mixed results.\n",
    "2. **Family Support**: \n",
    "   - **Family Support (Low)** has a consistently negative coefficient across all three models, suggesting it has a negative relationship with the target variable.\n",
    "3. **Previous GPA**: \n",
    "   - **Previous GPA** shows a positive relationship with the target variable, especially in **Ridge** and **Lasso** regressions.\n",
    "4. **Program of Study**: \n",
    "   - **Engineering** has a positive impact in both **Linear and Ridge Regression**, indicating it has a favorable effect on the target variable.\n",
    "5. **Attendance Rate**: \n",
    "   - **Attendance Rate** positively influences the target variable in both **Ridge** and **Lasso Regression**, with a notable coefficient in **Lasso**.\n",
    "\n",
    "### Conclusion:\n",
    "- **Family Support** and **Study Resources** (especially online and tutoring) appear to have a major influence on the target variable across all models.\n",
    "- **Previous GPA** and **Attendance Rate** are also important predictors in Ridge and Lasso regressions.\n",
    "- **Program of Study (Engineering)** is a significant feature in Linear and Ridge regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the most influential features (sorted by absolute value) for each model\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot Linear Regression Coefficients\n",
    "plt.subplot(3, 1, 1)\n",
    "sorted_linear['Linear Regression Coefficients'].head(10).plot(kind='barh', color='skyblue')\n",
    "plt.title('Top 10 Influential Features (Linear Regression)', fontsize=16)\n",
    "plt.xlabel('Coefficient Value', fontsize=14)\n",
    "plt.ylabel('Features', fontsize=14)\n",
    "\n",
    "# Plot Ridge Regression Coefficients\n",
    "plt.subplot(3, 1, 2)\n",
    "sorted_ridge['Ridge Regression Coefficients'].head(10).plot(kind='barh', color='lightcoral')\n",
    "plt.title('Top 10 Influential Features (Ridge Regression)', fontsize=16)\n",
    "plt.xlabel('Coefficient Value', fontsize=14)\n",
    "plt.ylabel('Features', fontsize=14)\n",
    "\n",
    "# Plot Lasso Regression Coefficients\n",
    "plt.subplot(3, 1, 3)\n",
    "sorted_lasso['Lasso Regression Coefficients'].head(10).plot(kind='barh', color='lightgreen')\n",
    "plt.title('Top 10 Influential Features (Lasso Regression)', fontsize=16)\n",
    "plt.xlabel('Coefficient Value', fontsize=14)\n",
    "plt.ylabel('Features', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
